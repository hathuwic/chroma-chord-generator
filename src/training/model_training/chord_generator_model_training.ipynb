{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjWC3nJk0XRQ"
      },
      "source": [
        "# Chroma Histogram Generation Model - training notebook\n",
        "\n",
        "This notebook implements training of an LSTM model for generating chroma histograms.\n",
        "\n",
        "It uses two objects from the custom module `model_training_utils`:\n",
        "- `ChordsDatasetManager` - a class which handles all the necessary pre-processing steps to transform the dataset from the CSV file of melody chroma and chord chroma histograms, into tf.data.Dataset objects.\n",
        "- `ChordGeneratorModel` - a custom model consisting of three LSTM layers and a dense, fully connected output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikCEvDvm164v"
      },
      "source": [
        "### Handle imports and mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcwWF56pgyJ6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import json\n",
        "\n",
        "# # For running on Colab - import Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Update CWD to project folder\n",
        "# print(f\"Current working directory: {os.getcwd()}\")\n",
        "# if os.getcwd() != \"/content/drive/My Drive/Norway/Thesis\":\n",
        "#     os.chdir(\"./drive/My Drive/Norway/Thesis/\")\n",
        "#     print(f\"Working directory updated to: {os.getcwd()}\")\n",
        "\n",
        "# Load the dataset handler\n",
        "from model_training_utils.dataset_manager import ChordsDatasetManager\n",
        "\n",
        "# Load the untrained model\n",
        "from model_training_utils.chord_generator_model import ChordGeneratorModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrkEiXwH2PIp"
      },
      "source": [
        "### Print useful info about Tensorflow including connected GPU/TPU to runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YH0BTrvgyJ8"
      },
      "outputs": [],
      "source": [
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
        "print(\"# of CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
        "print(\"# of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Check TPU availability\n",
        "tpu_available = False\n",
        "devices = tf.config.list_logical_devices()\n",
        "for device in devices:\n",
        "    if device.device_type == 'TPU':\n",
        "        tpu_available = True\n",
        "        break\n",
        "\n",
        "print(f\"TPU available: {tpu_available}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUUtvi-W2bWi"
      },
      "source": [
        "### Define handy functions for getting system time (in GMT if using Google Colab) and creating necessary save paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FArVpXHzgyJ9"
      },
      "outputs": [],
      "source": [
        "def now():\n",
        "    # Get current date and time and generate string\n",
        "    now = datetime.datetime.now()\n",
        "    now_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "    return now_string\n",
        "\n",
        "\n",
        "def model_save_paths(sequence_length, batch_size, learning_rate, LSTM_dropout, epochs):\n",
        "    model_save_location = f\"./trained_models/{now()}_chord_generator_sq-{sequence_length}_btch-{batch_size}_lr-{learning_rate}_dropout-{LSTM_dropout}_epoch-{epochs}\"\n",
        "    history_save_location = f\"./trained_models/history/{now()}_chord_generator_sq-{sequence_length}_btch-{batch_size}_lr-{learning_rate}_dropout-{LSTM_dropout}_epoch-{epochs}.json\"\n",
        "\n",
        "    return (model_save_location, history_save_location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j05v8ri82rwm"
      },
      "source": [
        "### Define model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYb502R1gyJ9"
      },
      "outputs": [],
      "source": [
        "test_size = 0.3\n",
        "\n",
        "sequence_length = 8\n",
        "batch_size = 64\n",
        "learning_rate = 0.0001\n",
        "dropout = 0.375\n",
        "\n",
        "num_inputs = 13\n",
        "num_outputs = 12\n",
        "\n",
        "lstm1_units = 512\n",
        "lstm2_units = 1024\n",
        "lstm3_units = 512\n",
        "\n",
        "input_shape = (None, sequence_length, num_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf5fsxbx2zUI"
      },
      "source": [
        "### Load and process dataset - requires a chroma histograms dataset (not included in this repo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIENezqTgyJ9"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"./datasets/Lakh/Lakh_chords_dataset_2024_ALL.csv\"\n",
        "\n",
        "# Load dataset\n",
        "dataset_manager = ChordsDatasetManager(dataset_path)\n",
        "\n",
        "# Format dataset\n",
        "dataset_manager.format_dataset()\n",
        "\n",
        "# Split dataset into train and test sections\n",
        "dataset_manager.test_train_split(test_size=test_size, sequence_length=sequence_length, batch_size=batch_size)\n",
        "\n",
        "# Get dataset components as tf.data.Dataset objects\n",
        "dataset_train = dataset_manager.get_training_data()\n",
        "dataset_test = dataset_manager.get_test_data()\n",
        "\n",
        "# Print raw dataset DataFrame\n",
        "dataset_manager.get_raw_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtHimJ1h23Iu"
      },
      "source": [
        "### Create, build, compile, and analyse model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "CN3nVVkFgyJ9",
        "outputId": "4a5ba934-dd9d-4dc5-c1db-8f443fe6c27c"
      },
      "outputs": [],
      "source": [
        "# Initialise model\n",
        "model = ChordGeneratorModel(\n",
        "    lstm1_units,\n",
        "    lstm2_units,\n",
        "    lstm3_units,\n",
        "    num_inputs=num_inputs,\n",
        "    num_outputs=num_outputs,\n",
        "    dropout=dropout\n",
        ")\n",
        "\n",
        "model.build(input_shape)\n",
        "\n",
        "# Define evaluation metrics\n",
        "metric_accuracy = tf.keras.metrics.Accuracy()\n",
        "metric_mse = tf.keras.metrics.MeanAbsoluteError()\n",
        "metric_mspe = tf.keras.metrics.MeanAbsolutePercentageError()\n",
        "metric_r2 = tf.keras.metrics.R2Score()\n",
        "metric_rmse = tf.keras.metrics.RootMeanSquaredError()\n",
        "metrics = [metric_accuracy, metric_mse, metric_mspe, metric_r2, metric_rmse]\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss=tf.keras.losses.MeanSquaredLogarithmicError(),\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUQjIOu_29T9"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDZWNEgcgyJ9"
      },
      "outputs": [],
      "source": [
        "# Set number of training opochs\n",
        "epochs = 25\n",
        "\n",
        "# Define callbacks\n",
        "callback_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "callback_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=f\"./trained_models/model_checkpoints/{now()}_chord_generator_colab_sql-{sequence_length}_btch-{batch_size}_lr-{learning_rate}_dr-{dropout}\",\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    dataset_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=[callback_stop, callback_checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orpOxaOh3I1Z"
      },
      "source": [
        "### Save trained model and model history to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiuwkeSik8B7"
      },
      "outputs": [],
      "source": [
        "# Generate save paths for model and history json\n",
        "model_save_path, history_save_path = model_save_paths(sequence_length, batch_size, learning_rate, dropout, epochs)\n",
        "\n",
        "# Save model\n",
        "model.save(model_save_path)\n",
        "print(f\"Saved model to {model_save_path}\")\n",
        "\n",
        "# Save model history dict to json\n",
        "model_history_data = history.history\n",
        "json.dump(model_history_data, open(history_save_path, \"w+\"))\n",
        "print(f\"Saved model history to {history_save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoHjYcEs3P1P"
      },
      "source": [
        "### Run trained model on test dataset, then evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpU924jL3IEO"
      },
      "outputs": [],
      "source": [
        "output_data_pred = model.predict(dataset_test)\n",
        "output_data_test = dataset_manager.get_output_data_test()\n",
        "\n",
        "#R2 score\n",
        "print(f\"Coefficient of determination (r2 score): {sklearn.metrics.r2_score(output_data_test[:output_data_pred.shape[0]], output_data_pred.reshape(-1,12))}\")\n",
        "\n",
        "# Print sum of each chroma column from test set\n",
        "for i, column in enumerate(output_data_pred.T):\n",
        "    print(i, \":\\t\", column.sum() / output_data_pred.sum())\n",
        "\n",
        "# # Plot total loss for model\n",
        "loss_plot_path = f\"./trained_models/loss_plots/{now()}_chord_generator_loss_plot_sq-{sequence_length}_btch-{batch_size}_lr={learning_rate}_dropout-{dropout}_epoch-{epochs}.png\"\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(history.epoch, history.history['loss'], label='total loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Total Loss\")\n",
        "plt.title(\"Total Loss for LSTM Chord Generation Model\")\n",
        "plt.savefig(loss_plot_path, bbox_inches=\"tight\", dpi=100, transparent=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aITa7tCTjDrK"
      },
      "source": [
        "### Print evaluation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx0QFQOr2gqB"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(dataset_manager.get_test_data())\n",
        "\n",
        "for i, score_result in enumerate(score):\n",
        "    if i == 0:\n",
        "        print(f\"loss: {score_result}\")\n",
        "    else:\n",
        "        print(f\"{metrics[i-1].name}: {score_result}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
